<style>
    @media (min-width: 992px) {
      .col-lg-2 {
        flex: 0 0 auto;
        width: 19.66666667%;
      }
  }
  </style>
  <section id="speaker" class="section">
    <div class="container">

      <div class="section-title" data-aos="zoom-out">
        <h2>Talks</h2>
        <p>Invited Speakers</p>
      </div>

      <div class="columns is-multiline">
        <!--
        <div class="column is-one-third">
          <figure class="image is-square">
            <img src="assets/images/speakers/pieter_abbeel.jpg" alt="Pieter Abbeel">
          </figure>
        </div>
        <div class="column is-half">
          <p><a href="https://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel</a> is Professor and Director of the Robot Learning Lab at UC Berkeley [2008- ], Co-Director of the Berkeley AI Research (BAIR) Lab, Co-Founder of covariant.ai [2017- ], Co-Founder of Gradescope [2014- ], Advisor to OpenAI, Founding Faculty Partner AI@TheHouse venture fund, Advisor to many AI/Robotics start-ups. He works in machine learning and robotics. In particular his research focuses on making robots learn from people (apprenticeship learning), how to make robots learn through their own trial and error (reinforcement learning), and how to speed up skill acquisition through learning-to-learn (meta-learning). His robots have learned advanced helicopter aerobatics, knot-tying, basic assembly, organizing laundry, locomotion, and vision-based robotic manipulation. He has won numerous awards, including best paper awards at ICML, NIPS and ICRA, early career awards from NSF, Darpa, ONR, AFOSR, Sloan, TR35, IEEE, and the Presidential Early Career Award for Scientists and Engineers (PECASE). Pieter's work is frequently featured in the popular press, including New York Times, BBC, Bloomberg, Wall Street Journal, Wired, Forbes, Tech Review, NPR.</p>
        </div>
        -->

        <div class="column is-one-third">
          <figure class="image is-square">
            <img src="assets/images/speakers/chelsea_finn.jpg" alt="Chelsea Finn">
          </figure>
        </div>
        <div class="column is-half">
          <p><a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a> is an Assistant Professor in Computer Science and Electrical Engineering at Stanford University, the William George and Ida Mary Hoover Faculty Fellow, and a co-founder of Physical Intelligence (Pi). Her research interests lie in the capability of robots and other agents to develop broadly intelligent behavior through learning and interaction. To this end, her work has pioneered end-to-end deep learning methods for vision-based robotic manipulation, meta-learning algorithms for few-shot learning, and approaches for scaling robot learning to broad datasets. Her research has been recognized by awards such as the Sloan Fellowship, the IEEE RAS Early Academic Career Award, and the ACM doctoral dissertation award, and has been covered by various media outlets including the New York Times, Wired, and Bloomberg. Prior to joining Stanford, she received her Bachelor's degree in Electrical Engineering and Computer Science at MIT and her PhD in Computer Science at UC Berkeley.</p>
        </div>

        <div class="column is-one-third">
          <figure class="image is-square">
            <img src="assets/images/speakers/scott_kuindersma.jpg" alt="Scott Kuindersma">
          </figure>
        </div>
        <div class="column is-half">
            <p><a href="https://www.linkedin.com/in/scott-kuindersma-06a38152/">Scott Kuindersma</a> is the Senior Director of Robotics Research at Boston Dynamics where he leads behavior research on Atlas. Prior to joining Boston Dynamics, he was an Assistant Professor of Engineering and Computer Science at Harvard. Scott’s research explores intersections of machine learning and model-based control to improve the capabilities of humanoids and other dynamic mobile manipulators.</p>
        </div>

        <div class="column is-one-third">
          <figure class="image is-square">
            <img src="assets/images/speakers/yuke_zhu.jpg" alt="Yuke Zhu">
          </figure>
        </div>
        <div class="column is-half">
            <p><a href="https://www.cs.utexas.edu/~yukez/">Yuke Zhu</a> is an Assistant Professor in the Computer Science department of UT-Austin, where he directs the Robot Perception and Learning (RPL) Lab. He is also a core faculty at Texas Robotics and a senior research scientist at NVIDIA. He focuses on developing intelligent algorithms for generalist robots and embodied agents to reason about and interact with the real world. His research spans robotics, computer vision, and machine learning. He received his Master's and Ph.D. degrees from Stanford University. His works have won several awards and nominations, including the Best Conference Paper Award in ICRA 2019, Outstanding Learning Paper at ICRA 2022, Outstanding Paper at NeurIPS 2022, and Best Paper Finalists in IROS 2019, 2021, and RSS 2023. He received the NSF CAREER Award and the Amazon Research Awards.</p>

        </div>

        <!--<div class="column is-one-third">
          <figure class="image is-square">
            <img src="assets/images/speakers/jitendra_malik.jpeg" alt="Jitendra Malik">
          </figure>
        </div>
        <div class="column is-half">
          <p><a href="https://people.eecs.berkeley.edu/~malik/">Jitendra Malik</a> is Arthur J. Chick Professor of EECS at UC Berkeley. His research has spanned computer vision, machine learning, modeling of human vision, computer graphics, and most recently robotics. He has advised more than 70 Ph.D. students and postdocs, many of whom are now prominent researchers. His honors include numerous best paper prizes, the 2013 Distinguished Researcher award in computer vision, the 2016 ACM/AAAI Allen Newell Award, the 2018 IJCAI Award for Research Excellence in AI, and the 2019 IEEE Computer Society’s Computer Pioneer Award for “leading role in developing Computer Vision into a thriving discipline through pioneering research, leadership, and mentorship”. He is a member of the National Academy of Sciences,  the National Academy of Engineering, and the American Academy of Arts and Sciences.</p>
        </div>
        -->

        <div class="column is-one-third">
          <figure class="image is-square">
            <img src="assets/images/speakers/toru_lin.jpeg" alt="Toru Lin">
          </figure>
        </div>
        <div class="column is-half">
            <p><a href="https://toruowo.github.io/">Toru Lin</a> is a second-year PhD student at Berkeley AI Research (BAIR), advised by Jitendra Malik and Alexei Efros. Previously, she obtained her BSc and MEng from MIT EECS, under the supervision of Phillip Isola. During her undergraduate years at MIT, she was also advised by Jiajun Wu and Antonio Torralba. Before transferring to MIT, she was an undergraduate student at The University of Tokyo. She also has interned at DeepMind, Facebook, and Google. She is building real-world robotic systems that can improve themselves through interaction with the environment.</p>
        </div>

        <div class="column is-one-third">
          <figure class="image is-square">
            <img src="assets/images/speakers/xingxing_wang.jpeg" alt="Xingxing Wang">
          </figure>
        </div>
        <div class="column is-half">
            <p><a href="https://www.unitree.com/">Xingxing Wang</a> is the CEO of Unitree.</p>
        </div>

        <!--<div class="column is-one-third">
          <figure class="image is-square">
            <img src="assets/images/speakers/deepak_pathak.jpeg" alt="Deepak Pathak">
          </figure>
        </div>
        <div class="column is-half">
          <p><a href="https://www.cs.cmu.edu/~dpathak/">Deepak Pathak</a> is a faculty in the School of Computer Science at Carnegie Mellon University. He received his Ph.D. from UC Berkeley and his research spans computer vision, machine learning, and robotics. He is a recipient of the faculty awards from Google, Samsung, Sony, GoodAI, and graduate fellowship awards from Facebook, NVIDIA, Snapchat. His research has been featured in popular press outlets, including The Economist, The Wall Street Journal, Quanta Magazine, Washington Post, CNET, Wired, and MIT Technology Review among others. Deepak received his Bachelor's from IIT Kanpur with a Gold Medal in Computer Science. He co-founded VisageMap Inc. later acquired by FaceFirst Inc.</p>
        </div>
        -->

        <div class="column is-one-third">
          <figure class="image is-square">
            <img src="assets/images/speakers/moritz_baecher.jpeg" alt="Moritz Baecher">
          </figure>
        </div>
        <div class="column is-half">
            <p><a href="https://www.baecher.info/">Moritz Bächer</a> is a Research Scientist at Disney Research, where he leads the Computational Design and Manufacturing group. He is deeply passionate about solving real-world problems in computational robotics, fabrication, and architecture. His core expertise is the development of differentiable simulators to tackle complex design, control, and characterization problems in (soft) robotics, architecture, and computer graphics. Before joining Disney, he received a Ph.D. from the Harvard School of Engineering and Applied Sciences and graduated with a master’s from ETH Zurich.</p>
        </div>

        <div class="column is-one-third">
          <figure class="image is-square">
            <img src="assets/images/speakers/jonathan_hurst.jpeg" alt="Junathan Hurst">
          </figure>
        </div>
        <div class="column is-half">
            <p><a href="https://engineering.oregonstate.edu/people/jonathan-hurst">Jonathan Hurst</a> is a Professor of Robotics, co-founder of the Oregon State University Robotics Institute, and Chief Technology Officer and co-founder of Agility Robotics. He holds a B.S. in mechanical engineering and an M.S. and Ph.D. in robotics, all from Carnegie Mellon University. His university research focuses on understanding the fundamental science and engineering best practices for legged locomotion. Investigations range from numerical studies and analysis of animal data, to simulation studies of theoretical models, to designing, constructing, and experimenting with legged robots for walking and running, and more recently, using machine learning techniques merged with more traditional control to enable highly dynamic gaits. Agility Robotics is extending this research to commercial applications for robotic legged mobility, working towards a day when robots can go where people go, generate greater productivity across the economy, and improve quality of life for all.</p>
        </div>

        <div class="column is-one-third">
          <figure class="image is-square">
            <img src="assets/images/speakers/vikash_kumar.png" alt="Vikash Kumar">
          </figure>
        </div>
        <div class="column is-half">
            <p><a href="https://vikashplus.github.io/">Vikash Kumar</a> is an adjunct professor at the Robotics Institute, CMU. He finished his Ph.D. from the University of Washington with Prof. Emo Todorov and Prof. Sergey Levine, where his research focused on imparting human-level dexterity to anthropomorphic robotic hands. He continued his research as a post-doctoral fellow with Prof. Sergey Levine at University of California Berkeley where he further developed his methods to work on low-cost scalable systems. He also spent time as a Research Scientist at OpenAI and Google-Brain where he diversified his research on low-cost scalable systems to the domain of multi-agent locomotion. He has also been involved with the development of the MuJoCo physics engine, now widely used in the fields of Robotics and Machine Learning. His works have been recognized with the best Master's thesis award, best manipulation paper at ICRA’16, best workshop paper ICRA'22, CIFAR AI chair '20 (declined), and have been widely covered with a wide variety of media outlets such as NewYorkTimes, Reuters, ACM, WIRED, MIT Tech reviews, IEEE Spectrum, etc.</p>
        </div>

        <div class="column is-one-third">
          <figure class="image is-square">
            <img src="assets/images/speakers/ziwen_zhuang.jpg" alt="Ziwen Zhuang">
          </figure>
        </div>
        <div class="column is-half">
            <p><a href="https://ziwenzhuang.github.io/">Ziwen Zhuang</a> is a research intern with Professor Hang Zhao at Shanghai Qi Zhi Institute. He is also a Master’s student at ShanghaiTech University, advised by Professor Soeren Schwertfeger. Ziwen’s research focuses on robot learning, especially athletic intelligence on legged robots. He published Robot Parkour Learning at CoRL 2023, which achieved Best System Award Finalist. Prior to that, he was a research intern at Carnegie Mellon University working with Professor David Held, and he was the algorithm leader of ShanghaiTech RoboMaster team.</p>
        </div>
        <!--<div class="column is-one-third">
          <figure class="image is-square">
            <img src="assets/images/speakers/manuel_yves_galliker.jpeg" alt="Manuel Yves Galliker">
          </figure>
        </div>
        <div class="column is-half">
            <p><a href="">Manuel Yves Galliker</a> is the team lead for controls and embedded at 1X Technologies. He holds a B.Sc. and M.Sc. in mechanical engineering with a focus on robotics, systems and controls from ETH Zurich. Manuel's research interests range from mechantronics to optimal, data-driven and reinforcement learned controls with a focus on locomotion and loco-manipulation. During his academic tenure, he dedicated his efforts of his master thesis to researching online gait generation for bipedal robots using Whole-Body Dynamics in a Nonlinear Model Predictive Control approach, contributing at ETH's Robotics Systems Lab and as a visiting researcher at Caltech's AMBER lab. This work culminated in a publication presented at the IEEE Humanoids 2022 conference, where it was distinguished as a finalist for the Best Paper Award. In his current role he is leading the R&D efforts on controls and embedded for the new bipedal Android NEO. In particular the team is aiming to develop whole body control and planning algorithms, ranging from Centroidal MPC to Whole-Body MPC and Reinforcement Learning, to enable consecutively more and more general loco-manipulation behaviors.</p>
        </div>
        -->
      </div>

  </section><!-- End Speaker Section -->


    <!-- ======= Organization Section ======= -->
    <section id="org" class="section">
      <div class="container">

        <div class="section-title" data-aos="zoom-out">
          <h2>Organization</h2>
          <p>Workshop Organizers</p>
        </div>

        <div class="columns is-multiline">
          <div class="column is-one-fifth">
            <div class="card-image has-text-centered">
              <figure class="image" style="height:100%;object-fit:cover;">
                <img class="is-rounded" src="assets/images/organizers-square/pieter_abbeel.jpg" alt="Pieter Abbeel">
              </figure>
            </div>
            <div class='card-content has-text-centered'>
              <h4><a href="https://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel</a></h4>
                <strong>Professor at UC Berkeley</strong>
            </div>
          </div>
          <div class="column is-one-fifth">
            <div class="card-image has-text-centered">
              <figure class="image" style="height:100%;object-fit:cover;">
                <img class="is-rounded" src="assets/images/organizers-square/carlo_sferrazza.jpeg" alt="Carlo Sferrazza">
              </figure>
            </div>
            <div class='card-content has-text-centered'>
              <h4><a href="https://sferrazza.cc/">Carlo Sferrazza</a></h4>
              <strong>Postdoc at UC Berkeley</strong>
            </div>
          </div>
          <div class="column is-one-fifth">
            <div class="card-image has-text-centered">
              <figure class="image" style="height:100%;object-fit:cover;">
                <img class="is-rounded" src="assets/images/organizers-square/xingyu_lin.png" alt="Xingyu Lin">
              </figure>
            </div>
            <div class='card-content has-text-centered'>
              <h4><a href="https://xingyu-lin.github.io/">Xingyu Lin</a></h4>
              <strong>Postdoc at UC Berkeley</strong>
            </div>
          </div>
          <div class="column is-one-fifth">
            <div class="card-image has-text-centered">
              <figure class="image" style="height:100%;object-fit:cover;">
                <img class="is-rounded" src="assets/images/organizers-square/youngwoon_lee.png" alt="Youngwoon Lee">
              </figure>
            </div>
            <div class='card-content has-text-centered'>
              <h4><a href="https://youngwoon.github.io/">Youngwoon Lee</a></h4>
              <strong>Assistant Professor at Yonsei Unviersity</strong>
            </div>
          </div>
    </section>

    <!-- ======= PC Section ======= -->
    <section id="pc" class="section">
        <div class="container">

          <div class="section-title" data-aos="zoom-out">
            <!-- <h2>Organization</h2> -->
            <p>Program Committee</p>
          </div>

          <div class="row">
              <!-- Maarten Sap (AI2), Jack Hessel (AI2), Keisuke Sakaguchi (AI2), Prithviraj Ammanabrolu (AI2), Tuhin Chakrabarty (Columbia), Liwei Jiang (UW), Alisa Liu (UW), Rowan Zellers (UW), Lianhui Qin (UW), Ximing Lu (UW), Michi Yasunaga (Stanford), Xikun Zhang (Stanford), Deniz Bayazit (EPFL), Silin Gao (EPFL), Aman Madaan (CMU), Khyathi Chandu (CMU), Yanai Elazar (Bar-Ilan), Avijit Thawani (USC), Pei Zhou (USC), Yu Hou (USC), Anurag Acharya (Florida International), Sarah Wiegreffe  (Georgia Tech), Abhilasha Sancheti (UMD), Neha Srikanth (UMD), Sheng Zhang (Microsoft), Yue Dong (McGill), Denis Emelin (Edinburgh), Simon Razniewski (MPI), Filip ilievski (USC ISI), Mayank Kejriwal (USC ISI), Jeff Da (AI2), Sumit Bhatia (Adobe Research), Manuel Ciosici (USC ISI), Chandra Bhagavatula (AI2), Ronan Le Bras (AI2), Emily Allaway (Columbia), Hongyu Ren (Stanford), Max Forbes (UW), Neha Srikanth (UMD), John Hewitt (Stanford), Shikhar Murty (Stanford), Eric Mitchell (Stanford), Shaobo Cui (EPFL), Lisa Bauer (UNC), Faeze Brahman (UCSC)  -->

              <div style="float: left; width: 50%;">
                <ul class="no-bullets">
                  <li>Carlo Sferrazza (UC Berkeley)</li>
                  <li>Youngwoon Lee (Yonsei University)</li>
                </ul>
                </div>
                <div style="float: right; width: 50%;">
                <ul class="no-bullets">
                  <li>Xingyu Lin (UC Berkeley)</li>
                </ul>
                </div>

          </div>
        </div>
      </section><!-- End PC Section -->

